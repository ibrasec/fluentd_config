<source>
  @type tail
  <parse>
  @type none
  </parse>
  # reading logs from var log syslog
  path /var/log/syslog
  # add a tag of the recieved logs for first stage parsing 
  tag td.recieved
  # adding a pos_file is optional 
  pos_file /var/log/syslog.pos
</source>

# first stage parsing
# parsing the received log according to its hostname
# second phase parsing will be done depending on the hostname
<match td.recieved>
  @type rewrite_tag_filter
  <rule>
    key     message
    pattern (.*?)cisco-switch\D
    # overwrite the tag for messages recieved with this hostname
    tag a.a
  </rule>
  <rule>
    key     message
    pattern (.*?)TR-02\D
    # overwrite the tag for messages recieved with this hostname    
    tag b.b
  </rule>
  <rule>
    key     message
    pattern (.*?)GUML-01\D
    # overwrite the tag for messages recieved with this hostname        
    tag c.c
  </rule>
  <rule>
    key     message
    pattern (.*)ASA-\w+-\d+\s
    # overwrite the tag for messages recieved with this hostname            
    tag d.d
  </rule>  
  <rule>
    key     message
    pattern (.*?)\D
    # overwrite the tag for messages recieved with unrecognized hostname            
    tag else.else
  </rule>
</match>


# second phase parsing, to parse logs from cisco-switch
<filter a.*>
  @type parser
  key_name message
  <parse>
  @type grok
  # grok configuration
  <grok>        # to match     Jul  3 09:19:40 cisco-switch : 2018 Jul  3 09:19:26 EET: %AUTHPRIV-3-SYSTEM_MSG: pam_aaa:Authentication failed for user admin from 10.251.110.111 - sshd[5642]
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:_device_id}) : (%{YEAR:ryear}) (%{MONTH:rmonth})  (%{MONTHDAY:rday}) (%{TIME:rtime}) (EET|UTC): %(%{HOSTNAME:_facility})-(%{NONNEGINT:priority})-(%{WORD:nmonic}): (%{GREEDYDATA:message})
  </grok>
    <grok>        # to match     Jul  3 09:19:40 cisco-switch 123: 2018 Jul  3 09:19:26 EET: %AUTHPRIV-3-SYSTEM_MSG: pam_aaa:Authentication failed for user admin from 10.251.110.111 - sshd[5642]
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:device_id}) (%{INT:zebra}) : (%{YEAR:ryear}) (%{MONTH:rmonth})  (%{MONTHDAY:rday}) (%{TIME:rtime}) (EET|UTC): %(%{HOSTNAME:_facility})-(%{NONNEGINT:priority})-(%{WORD:nmonic}): (%{GREEDYDATA:message})
  </grok>
  </parse>
</filter>


# second phase parsing, to parse logs from TR-01
<filter b.*>
  @type parser
  key_name message
  <parse>
  @type grok
  # grok configuration
  <grok>        # to match       Jul  3 09:40:01 TR-02 systemd: Starting Session 69159 of user root.
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{USERNAME:device_id}) (%{USERNAME:systemd}):(%{GREEDYDATA:message})
  </grok>
  </parse>
</filter>



# second phase parsing, to parse logs from GUML-01
<filter c.*>
  @type parser
  key_name message
  <parse>
  @type grok
  # grok configuration
  <grok>        # to match GUML-01
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) (%{WORD:service}): (%{WORD:severity}) (%{GREEDYDATA:message})
  </grok>
  </parse>
</filter>


# second phase parsing, to parse logs from ASA-something-number
<filter d.*>
  @type parser
  key_name message
  <parse>
      @type grok
      # spicify the pattern file's path
      custom_pattern_path /etc/fluent/patterns/firewalls
      # grok configuration      
      <grok>      
      # ASA-2-106001
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW106001:message})
      </grok>
      <grok>
      # ASA-2-106006, ASA-2-106007, ASA-2-106010
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW106006_106007_106010:message})
      </grok>  
      <grok>      
      # ASA-3-106014
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW106014:message})
      </grok>
      <grok>
      # ASA-6-106015
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW106015:message})
      </grok>
      <grok>
      # ASA-1-106021
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW106021:message})
      </grok>
      <grok>
      # ASA-4-106023
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW106023:message})
      </grok>
      <grok>
      # ASA-5-106100
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW106100:message})
      </grok>
      <grok>
      # ASA-6-110002
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW110002:message})
      </grok>
      <grok>
      # ASA-6-302010
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW302010:message})
      </grok>
      <grok>
      # ASA-6-302013, ASA-6-302014, ASA-6-302015, ASA-6-302016
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW302013_302014_302015_302016:message})
      </grok>
      <grok>
      # ASA-6-302020, ASA-6-302021
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW302020_302021:message})
      </grok>
      <grok>
      # ASA-6-305011
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW305011:message})
      </grok>
      <grok>
      # ASA-3-313001, ASA-3-313004, ASA-3-313008
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW313001_313004_313008:message})
      </grok>
      <grok>
      # ASA-4-313005
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW313005:message})
      </grok>
      <grok>
      # ASA-4-402117
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW402117:message})
      </grok>
      <grok>
      # ASA-4-402119
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW402119:message})
      </grok>
      <grok>
      # ASA-4-419001
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW419001:message})
      </grok>
      <grok>
      # ASA-4-419002
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW419002:message})
      </grok>
      <grok>
      # ASA-4-500004
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW500004:message})
      </grok>
      <grok>
      # ASA-6-602303, ASA-6-602304
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW602303_602304:message})
      </grok>
      <grok>
      # ASA-7-710001, ASA-7-710002, ASA-7-710003, ASA-7-710005, ASA-7-710006
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW710001_710002_710003_710005_710006:message})
      </grok>
      <grok>
      # ASA-6-713172
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW713172:message})
      </grok>
      <grok>
      # ASA-4-733100
      pattern (%{SYSLOGTIMESTAMP:timestamp}) (%{HOSTNAME:host}) : %ASA-(%{INT:severity})-(%{INT:event_id}): (%{CISCOFW733100:message})
      </grok>
  </parse>
</filter>


# to just return the message if its hostname is unspecified above
<filter else.*>
  @type parser
  key_name message
  <parse>
  @type grok
  # grok configuration
  <grok>        # to match any other message
      pattern (%{GREEDYDATA:message})
  </grok>
  </parse>
</filter>


<match *.*>
  @type copy
  <store>
     @type elasticsearch
     logstash_format true
     logstash_prefix toki
     flush_interval 5s
     Content_Type application/json
     template_name new.json
     template_file /etc/fluent/elastic_template/new.json
     template_overwrite true
  </store>
  <store>
     @type stdout
  </store>
</match>

# optinal match if a clear tag is to be inserted 
# on the first stage parsing, this is like drop any 
# logs recieved with the word "clear" found in the tag
<match clear>
  @type null
</match>

	  
